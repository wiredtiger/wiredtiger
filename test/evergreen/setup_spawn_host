#!/bin/bash

archive_fail() {
    echo "Error: archive [${1}] not found." >&2
}

cd $HOME # workaround EVG-12829

TOOLCHAIN_ROOT=/opt/mongodbtoolchain/v4

# Communicate to users that logged in before the script started that nothing is ready.
wall "The setup_spawn_host script has just started setting up the debugging environment."

# Make a directory on the larger EBS volume. Soft-link it under the home directory. The smaller home
# volume can have trouble particularly with coredumps from sharded timeouts.
mkdir -p /data/wiredtiger
ln -s /data/wiredtiger .
cd wiredtiger

# Discover and unarchive necessary files and source code. This will put mongo binaries and their
# partner .debug files in the same `debug/bin` directory. The `bin` directory will later be symbolic
# linked into the top-level (`debug`) directory. Shared library files and their debug symbols will
# be dumped into a `debug/lib` directory for tidiness. The mongo `<reporoot>/src/` directory is soft
# linked as `debug/src`. The .gdbinit file assumes gdb is being run from the `debug` directory.
WT_ARCHIVE=$(ls /data/mci/artifacts-*/*.tgz 2>/dev/null)
if [[ -n $WT_ARCHIVE ]]; then
    tar --wildcards --strip-components=1 -xzf $BIN_ARCHIVE
else
    archive_fail "bin"
fi

# Symbolic linking all of the executable files is sufficient for `gdb ./mongod ./dump_mongod.core`
# to succeed. This inadvertantly also links in the ".debug" files which is unnecessary, but
# harmless. gdb expects the .debug files to live adjacent to the physical binary.
find bin -type f -perm -o=x -exec ln -s {} cmake_build \;

cat >> ~/.profile <<EOF
# Coredumps generated by a toolchain built mongodb can be problematic when examined with the system
# gdb.
alias gdb='${TOOLCHAIN_ROOT}/bin/gdb'
alias g++='${TOOLCHAIN_ROOT}/bin/g++'
alias gcc='${TOOLCHAIN_ROOT}/bin/gcc'
alias python3='${TOOLCHAIN_ROOT}/bin/python3'

$WT_TOPDIR/TCMALLOC_LIB/lib
export LD_LIBRARY_PATH="${HOME}/wiredtiger/cmake_build:${HOME}/wiredtiger/TCMALLOC_LIB/LIB:$LD_LIBRARY_PATH"
EOF

    echo 'if [ -f ~/.profile ]; then
    . ~/.profile
fi' >> .bash_profile

# Send a Slack notification as the very last thing the setup_spawn_host script does.
# This way a Server engineer can temporarily forget about the Evergreen host they spawned until the
# paths and environment variables are configured as intended for when they first connect.
ssh_user=$(whoami)
evg_credentials_pathname=~/.evergreen.yml
evg_binary_pathname=evergreen

wall "The setup_spawn_host script has completed, please relogin to ensure the right environment variables are set."

slack_user=$(awk '{if ($1 == "user:") print $2}' "$evg_credentials_pathname")
# Refer to the https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html
# documentation for more information on the AWS instance metadata endpoints.
aws_metadata_svc="http://169.254.169.254"
aws_token=$(curl -s -X PUT "$aws_metadata_svc/latest/api/token" -H 'X-aws-ec2-metadata-token-ttl-seconds: 60')
ssh_host=$(curl -s -H "X-aws-ec2-metadata-token: $aws_token" "$aws_metadata_svc/latest/meta-data/public-hostname")
slack_message="The setup_spawn_host script has finished setting things up. Please run "'```'"ssh $ssh_user@$ssh_host"'```'" to log in."

# The Evergreen spawn host is expected to be provisioned with the user's .evergreen.yml credentials.
# But in case something unexpected happens we don't want the setup_spawn_host script itself
# to error.
if [[ -n "${slack_user}" ]]; then
    "$evg_binary_pathname" --config "$evg_credentials_pathname" notify slack -t "@$slack_user" -m "$slack_message"
fi
